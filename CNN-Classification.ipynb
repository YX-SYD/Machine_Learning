{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers,utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing data:**  \n",
    "1. Unzip data\n",
    "2. Reshape image to (128,128) and generate three-channel (RBG) images\n",
    "3. Using PIL build-in function to normalize (min-max normalization) and equalize data\n",
    "4. Save the preprocessed data to target directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = (128,128)\n",
    "rootdir = \"./unzip/gear_images/*/*\"\n",
    "for filename in glob.iglob(rootdir, recursive=True):\n",
    "    im = Image.open(filename)\n",
    "    im.thumbnail(size)\n",
    "    layer = Image.new('RGB', size, (255,255,255))\n",
    "    layer.paste(im)\n",
    "    \n",
    "    im_e = ImageOps.equalize(layer)\n",
    "    im_n = ImageOps.autocontrast(layer,5)\n",
    "    \n",
    "    newpath_e=filename.replace(\"gear_images\",\"e_images\")\n",
    "    newpath_n=filename.replace(\"gear_images\",\"n_images\")\n",
    "    new_dir_e = os.path.dirname(newpath_e)\n",
    "    new_dir_n = os.path.dirname(newpath_n)\n",
    "    \n",
    "    if not os.path.exists(new_dir_e):\n",
    "        os.makedirs(new_dir_e)\n",
    "    \n",
    "    if not os.path.exists(new_dir_n):\n",
    "        os.makedirs(new_dir_n)\n",
    "    \n",
    "    #print(newpath_e)\n",
    "    im_e.save(newpath_e)\n",
    "    im_n.save(newpath_n)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare labels:**  \n",
    "From the name of sub-directories to generate targe labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preparing y labels\n",
    "def label_code(rootdir):\n",
    "    label_dict={}\n",
    "    count = 0\n",
    "    for filename in glob.iglob(rootdir, recursive=True):\n",
    "        label_name = filename.split('/')[-2]\n",
    "        if label_name not in label_dict.keys():\n",
    "            label_dict[label_name] = count\n",
    "            count += 1\n",
    "    return label_dict\n",
    "\n",
    "rootdir = \"./unzip/e_images/*/*\"\n",
    "label_map = label_code(rootdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare the input data to CNN model:**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1591, 12)\n"
     ]
    }
   ],
   "source": [
    "#preparing data\n",
    "images=[]\n",
    "y=[]\n",
    "\n",
    "for filename in glob.iglob(rootdir, recursive=True):\n",
    "    im = np.array(Image.open(filename))\n",
    "    images.append(im)\n",
    "    \n",
    "    label_name = filename.split('/')[-2]\n",
    "    y.append(label_map[label_name])\n",
    "\n",
    "images = np.array(images)\n",
    "y = np.array(y)\n",
    "(x_train, x_test, y_train, y_test) = train_test_split(images, y, test_size=0.25, random_state=32)\n",
    "\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255  #normalization is critical for the correct result\n",
    "x_test /= 255\n",
    "\n",
    "print(np.shape(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "**Construct CNN:**  \n",
    "1. Convolutional layer*2\n",
    "2. Pooling layer\n",
    "3. Convolutional layer\n",
    "4. Pooling layer\n",
    "5. Flatten\n",
    "6. Full connection layer\n",
    "7. Drop out layer\n",
    "8. Full connection layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 125, 125, 64)      3136      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 122, 122, 64)      65600     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 58, 58, 128)       131200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 29, 29, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 107648)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               27558144  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                3084      \n",
      "=================================================================\n",
      "Total params: 27,761,164\n",
      "Trainable params: 27,761,164\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#prepare CNN model\n",
    "filter_size = (4,4)\n",
    "num_classes = 12\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, filter_size, activation='relu', input_shape=(128, 128, 3)))\n",
    "model.add(Conv2D(64, filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, filter_size, activation='relu'))\n",
    "#model.add(Conv2D(128, filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "opt = optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1591/1591 [==============================] - 405s 254ms/step - loss: 2.5100 - acc: 0.2175\n",
      "Epoch 2/20\n",
      "1591/1591 [==============================] - 403s 254ms/step - loss: 1.7354 - acc: 0.4481\n",
      "Epoch 3/20\n",
      "1591/1591 [==============================] - 424s 266ms/step - loss: 1.3270 - acc: 0.5921\n",
      "Epoch 4/20\n",
      "1591/1591 [==============================] - 608s 382ms/step - loss: 1.0915 - acc: 0.6688\n",
      "Epoch 5/20\n",
      "1591/1591 [==============================] - 482s 303ms/step - loss: 0.9639 - acc: 0.7071\n",
      "Epoch 6/20\n",
      "1591/1591 [==============================] - 420s 264ms/step - loss: 0.8076 - acc: 0.7498\n",
      "Epoch 7/20\n",
      "1591/1591 [==============================] - 407s 256ms/step - loss: 0.7091 - acc: 0.7825\n",
      "Epoch 8/20\n",
      "1591/1591 [==============================] - 407s 256ms/step - loss: 0.5756 - acc: 0.8278\n",
      "Epoch 9/20\n",
      "1591/1591 [==============================] - 406s 255ms/step - loss: 0.5932 - acc: 0.8209\n",
      "Epoch 10/20\n",
      "1591/1591 [==============================] - 409s 257ms/step - loss: 0.4242 - acc: 0.8762\n",
      "Epoch 11/20\n",
      "1591/1591 [==============================] - 412s 259ms/step - loss: 0.4001 - acc: 0.8843\n",
      "Epoch 12/20\n",
      "1591/1591 [==============================] - 407s 256ms/step - loss: 0.3436 - acc: 0.9001\n",
      "Epoch 13/20\n",
      "1591/1591 [==============================] - 405s 255ms/step - loss: 0.2962 - acc: 0.9177\n",
      "Epoch 14/20\n",
      "1591/1591 [==============================] - 438s 275ms/step - loss: 0.2315 - acc: 0.9359\n",
      "Epoch 15/20\n",
      "1591/1591 [==============================] - 413s 259ms/step - loss: 0.2017 - acc: 0.9415\n",
      "Epoch 16/20\n",
      "1591/1591 [==============================] - 408s 256ms/step - loss: 0.1831 - acc: 0.9434\n",
      "Epoch 17/20\n",
      "1591/1591 [==============================] - 434s 273ms/step - loss: 0.1746 - acc: 0.9510\n",
      "Epoch 18/20\n",
      "1591/1591 [==============================] - 406s 255ms/step - loss: 0.1011 - acc: 0.9761\n",
      "Epoch 19/20\n",
      "1591/1591 [==============================] - 410s 257ms/step - loss: 0.1524 - acc: 0.9617\n",
      "Epoch 20/20\n",
      "1591/1591 [==============================] - 437s 275ms/step - loss: 0.0721 - acc: 0.9793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa621794a20>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the trained model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('./cnn_weights_1.h5')\n",
    "model.save('./cnn_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show the model evaluzation results:**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.4705527427337937\n",
      "acc 0.903954801698638\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0, batch_size=128)\n",
    "for name,value in zip(model.metrics_names, score):\n",
    "    print(name, value) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
